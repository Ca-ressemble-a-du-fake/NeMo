#!/bin/bash
python speech_to_text_ctc_bpe_ts.py \
--config-path=../conf/conformer \
--config-name=conformer_ctc_bpe_ts_conformer.yaml \
model.tokenizer.type=bpe \
model.tokenizer.dir=/home/yangzhang/code/ts_asr/tokenizer_conformer/ctc_medium/tokenizer_spe_unigram_v128/ \
model.train_ds.manifest_filepath=/mnt/data/wsj/wsj0-3mix/manifests/tr_tsasr.json \
trainer.max_epochs=50 \
num_sources=3 \
model.validation_ds.manifest_filepath=/mnt/data/wsj/wsj0-3mix/manifests/cv_tsasr.json \
model.train_ds.max_duration=16 \
model.train_ds.mixing_portion=1.0 \
model.tokenizer.type=bpe \
trainer.num_sanity_val_steps=10 \
model.test_ds.manifest_filepath=/mnt/data/wsj/wsj0-3mix/manifests/tt_tsasr.json \
model.speaker_embeddings.freeze_decoder=True \
model.speaker_embeddings.freeze_encoder=True \
model.freeze_asr_decoder=False \
model.freeze_asr_encoder=False \
model.train_ds.batch_size=8 \
model.train_ds.synthetic_generation=True \
model.train_ds.num_workers=0 \
model.validation_ds.num_workers=0 \
model.validation_ds.batch_size=1 \
model.validation_ds.synthetic_generation=False \
model.test_ds.num_workers=0 \
model.test_ds.batch_size=1 \
model.test_ds.synthetic_generation=False \
model.test_ds.sample_rate=16000 \
trainer.devices=[0] \
trainer.log_every_n_steps=50 \
model.encoder.d_model=256 \
model.encoder.n_heads=4 \
model.encoder.n_layers=18 \
model.speaker_beam.n_layers=12 \
trainer.val_check_interval=1.0 \
model.optim.lr=2 \
+nemo_checkpoint_path=/home/yangzhang/code/ts_asr/stt_en_conformer_ctc_medium_v1.0.0/stt_en_conformer_ctc_medium.nemo
